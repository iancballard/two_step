{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for analyzing the behavioral data from the associative boosting task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import csv\n",
    "import matplotlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy\n",
    "import patsy\n",
    "import ast\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianballard/Dropbox/two_step_analysis/data/associative_boost/\n"
     ]
    }
   ],
   "source": [
    "home_dir = os.path.abspath('../') #where the data live\n",
    "data_dir = home_dir + '/data/associative_boost/'\n",
    "print data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "ignore_files = []\n",
    "data_files = glob.glob(data_dir + '*txt')\n",
    "data_files = [d for d in data_files if d.split('/')[-1] not in ignore_files]\n",
    "sub_ids = map(lambda f: f.split('/')[-1].split('.csv')[0],data_files)\n",
    "print(len(data_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fixup(sub_data,d):\n",
    "    if d in sub_data:\n",
    "        col = sub_data[d].dropna()     \n",
    "        sub_data[d] = col.values[0]    \n",
    "    return sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "for i,f in enumerate(data_files):\n",
    "    sub_data = []\n",
    "    with open(f, 'r') as myfile:\n",
    "        data = myfile.read() \n",
    "    d = data.split('\\n')[:-1]\n",
    "    for line in d:\n",
    "        try:\n",
    "            line = line.replace('null','-1') #ast doesnt like null objects\n",
    "            line = ast.literal_eval(line)\n",
    "            line = {key:str(val) for key, val in line.iteritems()}\n",
    "            line = pd.DataFrame(line, index=[0])\n",
    "            sub_data.append(line)\n",
    "        except:\n",
    "            print i,line\n",
    "    sub_data = pd.concat(sub_data).reset_index()\n",
    "    sub_data['sub'] = f.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    #clean up demongraphic info\n",
    "    demographic = ['age','cig','drg','eth','his','oth','numPieces','number','text']\n",
    "    for d in demographic:\n",
    "        sub_data = fixup(sub_data,d)\n",
    "    sub_data = sub_data.drop('index', 1)\n",
    "    \n",
    "    all_data.append(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat(all_data)\n",
    "all_data = all_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subs = list(set(all_data['sub']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "bad_subs = []\n",
    "for s in subs:\n",
    "    sub_df = all_data[all_data['sub'] == s]\n",
    "    if len(set(sub_df['loopNumber'].values)) != 4: #3 loops plus NaN\n",
    "        bad_subs.append(s)\n",
    "    if sub_df[sub_df['name'] == 'twoStep'].shape[0] < 145:\n",
    "        bad_subs.append(s)\n",
    "    \n",
    "for s in bad_subs:\n",
    "    all_data = all_data[all_data['sub'] != s]\n",
    "subs = list(set(all_data['sub']))\n",
    "print len(subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze two step data for transition/reward interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "two_step = []\n",
    "for s in subs:\n",
    "    sub_df = all_data[all_data['sub'] == s]\n",
    "    ts = sub_df[sub_df['name'] == 'twoStep'].copy()\n",
    "    ts = ts[ts['reward'] != '-1'] #drop missed responses\n",
    "    \n",
    "    #block number\n",
    "    trial_num = ts['trialNum'].values\n",
    "    starts = np.where(trial_num == '0')[0]\n",
    "    block = []\n",
    "    for n,i in enumerate(starts):\n",
    "        if n < len(starts)-1:\n",
    "            b = np.zeros(starts[n+1] - i) + n\n",
    "        else:\n",
    "            b = np.zeros(len(trial_num) - i) + n\n",
    "        block.extend(b)\n",
    "    ts['block'] = block\n",
    "\n",
    "    #choice 1 (shifted)\n",
    "    choice_map = {'left':0,'right':1}\n",
    "    choice1 = [ast.literal_eval(x)['1'] for x in ts['response'].values]\n",
    "    choice1 = [choice_map[x] for x in choice1]\n",
    "\n",
    "    stay_indicator = [np.NaN]\n",
    "    for n,c in enumerate(choice1):\n",
    "        if n>0:\n",
    "            if c == choice1[n-1]:\n",
    "                stay_indicator.append('stay')\n",
    "            else:\n",
    "                stay_indicator.append('switch')\n",
    "    choice1.append(np.NaN)\n",
    "    choice1 = choice1[1:]\n",
    "    ts['choice1'] = choice1\n",
    "    ts['stay'] = stay_indicator\n",
    "\n",
    "    #trial type\n",
    "    stage2 = [ast.literal_eval(x).keys()[1] for x in ts['response'].values]\n",
    "    ttype = []\n",
    "    for choice,stage in zip(choice1,stage2):\n",
    "        if (choice == 0 and stage == '2a') or (choice == 1 and stage == '2b'):\n",
    "            ttype.append('common')\n",
    "        else:\n",
    "            ttype.append('rare')\n",
    "    ts['ttype'] = ttype\n",
    "\n",
    "    ts = ts[['ttype','reward','choice1','stay','sub','block']]\n",
    "    ts = ts.dropna()\n",
    "    two_step.append(ts)\n",
    "two_step = pd.concat(two_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#normalize regressors\n",
    "stay_map = {'switch':-1,'stay':1}\n",
    "trans_map = {'common':1,'rare':-1}\n",
    "two_step['ttype_bin'] = map(lambda x: trans_map[x],two_step['ttype'])\n",
    "two_step['stay_bin'] = map(lambda x: stay_map[x],two_step['stay'])\n",
    "two_step['reward'] = 2*(np.array(map(float,two_step['reward'])) - .5)\n",
    "# two_step['correct'] = all_data['correct'] - .5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logistic regression analysis\n",
    "ttype_betas = []\n",
    "stay_betas = []\n",
    "rew_betas = []\n",
    "intercept_betas = []\n",
    "interaction_betas = []\n",
    "# correct_betas = []\n",
    "score = []\n",
    "\n",
    "      \n",
    "for n,sub in enumerate(subs):\n",
    "    sub_data = two_step[two_step['sub'] == sub] \n",
    "\n",
    "    y, X = dmatrices('stay_bin ~ ttype_bin + reward + reward:ttype_bin + C(block)',\n",
    "                 sub_data,return_type=\"dataframe\")\n",
    "\n",
    "    y = np.ravel(y)\n",
    "    model = LogisticRegression()\n",
    "    model = model.fit(X, y)\n",
    "    betas = pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))\n",
    "    coef = model.coef_[0]\n",
    "    if len(coef) == 6:\n",
    "        score.append(model.score(X, y))\n",
    "        intercept_betas.append(coef[0])\n",
    "        ttype_betas.append(coef[3])\n",
    "        rew_betas.append(coef[4])\n",
    "        interaction_betas.append(coef[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.880794701987\n",
      "0.610738255034\n",
      "0.754966887417\n",
      "0.841059602649\n",
      "0.867549668874\n",
      "0.854304635762\n",
      "0.615894039735\n",
      "['A1T6RFUU0OTS0M', 'A2CF2BD4Q0ZDJN', 'A3OYUJ6E6BJS4H', 'A2OO4PG3LBLP5I', 'A2UYNLN1B4JV8Y', 'AFEJL4G9L6XN7', 'A1SLJKNSNHOJRN', 'A28F1ZWZ9H0RHA', 'A3RHGIM99R25Q9', 'A2JJRPI671MF0U', 'A6P0CC8HHZLFJ', 'AS7WV8YWOEO55', 'A2YKW761AK4ZGY', 'A18U9WMYFYJPR6', 'AFXE92S04IYHY', 'A3B7TNVOISSZ2O']\n",
      "[-0.047462249007395617, 0.14172164909390883, 0.33203062161682162, 0.25158364412436152, 0.33049313920921336, 0.037988698752173158, 0.33082290975458684, 0.014523221401805333, 0.034313435103291913, 0.20633716463556023, -0.063910915514898983, -0.10585549234668544, 0.21297893899926931, 0.25318622398598906, 0.033924941378636539, 0.10436261715327294, 0.4377805245113196, 0.11286696679137791, -0.098760244656364321, 0.1583888457103694, -0.17342526201356825, -0.00061560275378196624, -0.31880862825881789]\n",
      "[-0.12047757557991201, -0.0019498965164847345, -0.18052311234887417, -0.43563173392480298, 0.099249612940962309, 0.063252316925188151, -0.5111426757516373, -0.16513506092833918, -0.026721024112136758, 0.26527392396009819, -0.10155062892581494, -0.034286913911517176, 0.014241797511228988, 0.15587911145687844, -0.18863453286657683, -0.053189946639748978, -0.29610196698056213, 0.5224385538790085, 0.41403146083742115, 0.052651787057960663, 0.40809507734198136, -0.032163486692713024, 0.11376464965623424]\n"
     ]
    }
   ],
   "source": [
    "no_inter_subs = []\n",
    "for s,rew,inter,sc in zip(subs,rew_betas,interaction_betas,score):\n",
    "    if inter < 0 or rew < 0:\n",
    "        no_inter_subs.append(s)\n",
    "    else:\n",
    "        print sc\n",
    "print no_inter_subs\n",
    "print interaction_betas\n",
    "print rew_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttype 0.110672246489 0.912879692466\n",
      "intercept 6.11488330984 3.73096271492e-06\n",
      "rew -0.0319306434176 0.974815280658\n",
      "interaction 2.45031775829 0.0226921106443\n",
      "score 0.761471355148 11.4313953676 1.00398943285e-10\n"
     ]
    }
   ],
   "source": [
    "t,p = scipy.stats.ttest_1samp(ttype_betas,0)\n",
    "print 'ttype',t,p\n",
    "\n",
    "t,p = scipy.stats.ttest_1samp(intercept_betas,0)\n",
    "print 'intercept',t,p\n",
    "\n",
    "t,p = scipy.stats.ttest_1samp(rew_betas,0)\n",
    "print 'rew',t,p\n",
    "\n",
    "t,p = scipy.stats.ttest_1samp(interaction_betas,0)\n",
    "print 'interaction',t,p\n",
    "\n",
    "t,p = scipy.stats.ttest_1samp(score,.5)\n",
    "print 'score',np.mean(score),t,p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze neutral trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_prop_targ(pre_post,block_df):\n",
    "    pre = block_df[block_df['pre_post'] == pre_post]\n",
    "    num_targ = np.sum(pre['target_indicator'])\n",
    "    num_choice_targ = np.sum(pre['choice'] == 'tgt')\n",
    "    prop_targ = num_choice_targ *1.0 / num_targ\n",
    "    return prop_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "neutral_choice = {'sub':[],'block':[],'pre_post':[],'prop':[]}\n",
    "for s in subs:\n",
    "    if s not in no_inter_subs:\n",
    "        sub_df = all_data[all_data['sub'] == s]\n",
    "        neutral = sub_df[sub_df['name'] == 'neutral'].copy()\n",
    "\n",
    "        ##parse out the block and the run numbers from the neutral trial numbers [0 to 9]\n",
    "        trial_num = neutral['trialNum'].values\n",
    "        neutral_starts = np.where(trial_num == '0')[0]\n",
    "        neutral_run = []\n",
    "        for n,i in enumerate(neutral_starts):\n",
    "            if n < len(neutral_starts)-1:\n",
    "                block = np.zeros(neutral_starts[n+1] - i) + n\n",
    "            else:\n",
    "                block = np.zeros(len(trial_num) - i) + n\n",
    "            neutral_run.extend(block)\n",
    "        neutral_run = map(int,neutral_run)\n",
    "        neutral['run'] = neutral_run\n",
    "\n",
    "        block_map = {0:0,1:0,2:1,3:1,4:2,5:2}\n",
    "        neutral['block'] = [block_map[x] for x in neutral_run]\n",
    "\n",
    "        prepost_map = {0:'pre',1:'post',2:'pre',3:'post',4:'pre',5:'post'}\n",
    "        neutral['pre_post'] = [prepost_map[x] for x in neutral_run]\n",
    "\n",
    "        #filter missed responses\n",
    "        fb = [ast.literal_eval(x).keys()[1] for x in neutral['stageOnsetTime'].values]\n",
    "        neutral['too_slow'] = [x!='tooslow' for x in fb]\n",
    "        neutral = neutral[neutral['too_slow'] == True]\n",
    "\n",
    "        #parse the choices\n",
    "        choice_map = {'left':0,'right':1}\n",
    "        choices = [ast.literal_eval(x)['1'] for x in neutral['response'].values]\n",
    "        choices = [choice_map[x] for x in choices]\n",
    "        neutral['response'] = choices\n",
    "\n",
    "        #parse the stimuli\n",
    "        stims = [ast.literal_eval(x) for x in neutral['stimuli'].values]\n",
    "        which_choice = [stim[choice] for stim,choice in zip(stims,choices)]\n",
    "        target_indicator = ['tgt' in x for x in stims]\n",
    "        neutral['target_indicator'] = target_indicator\n",
    "        neutral['choice'] = which_choice\n",
    "\n",
    "        #reaction time\n",
    "        respT = np.array([ast.literal_eval(x)['1'] for x in neutral['responseTime'].values])\n",
    "        onsetT = np.array([ast.literal_eval(x)['1'] for x in neutral['stageOnsetTime'].values])\n",
    "        neutral['RT'] = respT - onsetT\n",
    "\n",
    "        # neutral\n",
    "        for block in range(3):\n",
    "            block_df = neutral[neutral['block'] == block]\n",
    "            for pp in ['pre','post']:\n",
    "                prop_targ = get_prop_targ(pp,block_df)\n",
    "                neutral_choice['sub'].append(s)\n",
    "                neutral_choice['prop'].append(prop_targ)\n",
    "                neutral_choice['pre_post'].append(pp)\n",
    "                neutral_choice['block'].append(block)\n",
    "neutral_choice = pd.DataFrame(neutral_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block</th>\n",
       "      <th>prop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A142ZRU284W9O</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1A3TGZ7DKJWRW</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1C0H8G0YI15MN</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2TZJKKUN0LSHY</th>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3LZCR1FDVSVQ8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3QJJR5Y3XE92N</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM8OWAW9TUVLN</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXJSZ1BBVYIYL</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                block  prop\n",
       "sub                        \n",
       "A142ZRU284W9O       0 -0.25\n",
       "A1A3TGZ7DKJWRW      0 -0.25\n",
       "A1C0H8G0YI15MN      0  0.00\n",
       "A2TZJKKUN0LSHY      0  0.25\n",
       "A3LZCR1FDVSVQ8      0  0.25\n",
       "A3QJJR5Y3XE92N      0  0.00\n",
       "AM8OWAW9TUVLN       0 -0.25\n",
       "AXJSZ1BBVYIYL       0 -0.50"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_choice = neutral_choice[neutral_choice['block'] ==0]\n",
    "prop_diff = neutral_choice[neutral_choice['pre_post'] == 'post']['prop'].values \\\n",
    "    - neutral_choice[neutral_choice['pre_post'] == 'pre']['prop'].values\n",
    "neutral_choice = neutral_choice.groupby(['sub','block']).mean()\n",
    "neutral_choice.reset_index(inplace=True)  \n",
    "neutral_choice['prop'] = prop_diff\n",
    "neutral_choice.groupby('sub').mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0.,  3.,  0.,  0.,  2.,  0.,  0.,  2.]),\n",
       " array([-0.5  , -0.425, -0.35 , -0.275, -0.2  , -0.125, -0.05 ,  0.025,\n",
       "         0.1  ,  0.175,  0.25 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAECCAYAAAAb5qc/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFWbJS1JhlrwkFWbJS1Jh/weg5rdnbnagMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117ccd6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(prop_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.25, -0.25,  0.  ,  0.25,  0.25,  0.  , -0.25, -0.5 ])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1LAZ3AO0NYBC1\n",
      "A3N0QZ9ZKUCTCQ\n",
      "A3P5WIW36V70AI\n",
      "                id  reward                      Assignment\n",
      "0   A13UK1HPOJZVRO    0.58  3IJXV6UZ1XJFEMS4X0W5V4BDK0QIRE\n",
      "1   A13VIJ7G997ZCY    0.54  3OHYZ19UGC5XBRHQTKNOKBIPW4XAON\n",
      "2    A142ZRU284W9O    1.84  3T3IWE1XG6N5BZTFEX694L3H05ATQW\n",
      "3   A18U9WMYFYJPR6    2.06  33F859I566DS2K0VVLSUVD5U3BABHO\n",
      "4   A1A3TGZ7DKJWRW    2.18  3PDJHANYK5GMW8J0ZUBMKXJ2O016HF\n",
      "5   A1C0H8G0YI15MN    2.02  33UKMF9319KI3FL7V1049QE4KC5TT6\n",
      "6   A1CSWN23S8BHQY    0.62  3GFK2QRXX9H8AUEBPANHTUFP7TZ5WU\n",
      "7   A1EQN91S6T820I    0.56  33PPO7FECVFLDC9ZFZ1LQFU95YVID2\n",
      "8   A1KS9OHP5553CF    1.68  3YGXWBAF70HH0D46UE46C828GRPC4B\n",
      "10  A1SLJKNSNHOJRN    1.62  3NJM2BJS4W63P6QPSYWUF6D37NLCP2\n",
      "11  A1T6RFUU0OTS0M    1.92  3O6CYIULED1PV94QQBVP16757KUWUQ\n",
      "12  A27W025UEXS1G0    2.10  3SUWZRL0MYDACYSY9T3GZUMPWK96EZ\n",
      "13  A28F1ZWZ9H0RHA    2.26  3WZ36BJEV3GI7TRQVF9J9W8IDV7BTF\n",
      "14  A2CF2BD4Q0ZDJN    1.98  3D8YOU6S9EKR1UPKZTIL3C8SJI26U0\n",
      "15  A2JJRPI671MF0U    2.14  3KB8R4ZV1E7E2O5KBFACADTTOBXBGP\n",
      "16  A2OO4PG3LBLP5I    1.90  3UQGT4H58RFE9210V2ITPE38MWXCM1\n",
      "17  A2TZJKKUN0LSHY    1.96  3K3R2QNK8B3EJDRIX0LXNMZU9JA9UE\n",
      "18  A2UYNLN1B4JV8Y    1.38  3LKC68YZ3A3UI4KTUPJG20FGPY6OW5\n",
      "19  A2YKW761AK4ZGY    2.10  3IAEQB9FMEK3E7T44G50R63HKA1DWE\n",
      "20  A2ZRF4I5RTKN7G    1.94  39GHHAVOMFR48RAC46LSZCF35114JZ\n",
      "21  A3B7TNVOISSZ2O    1.86  336KAV9KYQSK02QOMS37GKXTYRH2YY\n",
      "22  A3LZCR1FDVSVQ8    2.04  3907X2AHF05QROYNV57O3T4HVW82PJ\n",
      "24  A3OYUJ6E6BJS4H    2.12  38F71OA9GTW47FDMRKU3684BZV1MFQ\n",
      "26  A3QJJR5Y3XE92N    2.14  3HMVI3QICJSDBH8S3O3TB1NO7VX1YV\n",
      "27  A3RHGIM99R25Q9    2.00  3WT783CTPBH1LCPF9TETKM8EQJ6CBH\n",
      "28   A6P0CC8HHZLFJ    2.30  3Q8GYXHFEP2ZWW868JNGH08MGNKC5G\n",
      "29   AB774I47XHB4K    0.72  3TAYZSBPLL8N4GEFNMBIYY9SH582S5\n",
      "30   AFEJL4G9L6XN7    2.42  39L1G8WVWQRCVEB4E3A3L7RBXK3135\n",
      "31   AFXE92S04IYHY    2.10  3FQ5JJ512LOL5JQ04W00Z0LGB7UKN7\n",
      "32   AM8OWAW9TUVLN    2.06  378XPAWRUCDNF56NVPAJ0EM3L65AIM\n",
      "33   ANQ0RLFEZ17W0    0.58  3KAKFY4PGU2NVK72MAV9D68XEL5I33\n",
      "34   AS7WV8YWOEO55    1.64  3DPNQGW4LLFSKWV5KNR3Q8AYK5I46F\n",
      "35   ATXD32K0HEP2C    0.62  3TXMY6UCAEOOPIR4SBBJFB3DB93CQ4\n",
      "36   AXJSZ1BBVYIYL    1.94  339ANSOTR52TRIF97GN8USPZP86IKV\n"
     ]
    }
   ],
   "source": [
    "# #calculate bonus for each subject (bonuses)\n",
    "all_data['reward'] = map(float,all_data['reward'])\n",
    "rew_data = all_data[['reward','id']].copy().dropna()\n",
    "bonuses = all_data.groupby(['id']).sum().dropna()['reward']* .02\n",
    "bonuses = bonuses.reset_index() \n",
    "\n",
    "bonuses['Assignment'] = np.NaN\n",
    "worker_data = pd.read_csv('../transaction_data/Transactions_2016-05-01_to_2016-06-03.csv')\n",
    "for sub in bonuses['id']:\n",
    "    assignment_id = worker_data[worker_data['Recipient ID'] == sub]['Assignment ID']\n",
    "    if len(assignment_id) > 0:\n",
    "        assignment_id = np.array(assignment_id)[0]\n",
    "        bonuses.ix[bonuses['id'] == sub,'Assignment'] = assignment_id\n",
    "    else:\n",
    "        print sub\n",
    "bonuses = bonuses.dropna()\n",
    "bonuses = bonuses.drop_duplicates()\n",
    "bonuses.to_csv('../transaction_data/payment2.txt',columns = ['Assignment','id','reward'],header = False, index = False)\n",
    "\n",
    "# payments = pd.read_csv(home_dir + '/transaction_data/logs_for_tamara_3_30.csv')\n",
    "# payments = payments.sort('Transaction Type')\n",
    "# payments.to_csv(home_dir + '/transaction_data/logs_for_tamara_3_30_sorted.csv')\n",
    "# print payments.groupby('Transaction Type').sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
